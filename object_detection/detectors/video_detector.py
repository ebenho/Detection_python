import cv2
import time
import os
from ultralytics import YOLO
from object_detection.utils.save_log import save_detection_log
from object_detection.config import Config

class VideoDetector:
    def __init__(self, model_path: str = "yolov8n.pt"):
        """
        Khá»Ÿi táº¡o VideoDetector vá»›i mÃ´ hÃ¬nh YOLO.

        Args:
            model_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file mÃ´ hÃ¬nh YOLO.
        """
        print("ğŸš€ Äang load model YOLO (CPU)...")
        self.model = YOLO(model_path)
        self.cap = None
        self.running_mode = None
        self.paused = False
        self.last_frame = None  # ThÃªm Ä‘á»ƒ lÆ°u frame cuá»‘i cÃ¹ng khi táº¡m dá»«ng

    def detect_video(self, video_path: str) -> bool:
        """
        Má»Ÿ vÃ  báº¯t Ä‘áº§u xá»­ lÃ½ video tá»« Ä‘Æ°á»ng dáº«n file.
        Args:
            video_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file video.
        Returns:
            bool: True náº¿u má»Ÿ video thÃ nh cÃ´ng, False náº¿u tháº¥t báº¡i.
        """
        if not os.path.exists(video_path):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y video: {video_path}")
            return False

        self.stop()
        self.current_video_path = video_path
        self.cap = cv2.VideoCapture(video_path)
        self.running_mode = "video"
        if not self.cap.isOpened():
            print(f"âŒ KhÃ´ng thá»ƒ má»Ÿ video: {video_path}. Kiá»ƒm tra Ä‘á»‹nh dáº¡ng hoáº·c codec.")
            return False
        try:
            fourcc = int(self.cap.get(cv2.CAP_PROP_FOURCC))
            codec = chr(fourcc & 0xFF) + chr((fourcc >> 8) & 0xFF) + chr((fourcc >> 16) & 0xFF) + chr((fourcc >> 24) & 0xFF)
            print(f"ğŸ“¹ Video codec: {codec}")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ kiá»ƒm tra codec: {str(e)}")
        return True

    def toggle_pause(self) -> bool:
        self.paused = not self.paused
        print(f"â¯ Video {'táº¡m dá»«ng' if self.paused else 'tiáº¿p tá»¥c'}.")
        return self.paused
    
    def process_stream(self) -> tuple:
        if self.cap is None or self.running_mode not in ("video", "camera"):
            print("âš ï¸ KhÃ´ng cÃ³ stream Ä‘á»ƒ xá»­ lÃ½.")
            return None, None, None
        
        if self.paused:
            if self.last_frame is not None:
                return self.last_frame, None, 0.0
            return None, None, None

        ret, frame = self.cap.read()
        if not ret:
            print("ğŸ“ Video Ä‘Ã£ káº¿t thÃºc.")
            return None, None, None

        frame_small = cv2.resize(frame, (320, 320))
        start = time.time()
        results = self.model(frame_small, verbose=False)
        annotated = results[0].plot()
        fps = 1 / (time.time() - start + Config.MIN_FPS)

        self.last_frame = annotated  # LÆ°u frame cuá»‘i cÃ¹ng
        detected_objects = []
        if len(results[0].boxes) > 0:
            for box in results[0].boxes:
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                label = self.model.names[cls]
                detected_objects.append((label, conf))
        if detected_objects:
            source = self.current_video_path if self.running_mode == "video" else "Live Stream"
            save_detection_log(self.running_mode.capitalize(), source, detected_objects)

        return annotated, results, fps
    
    def stop(self):
        """
        Dá»«ng video hoáº·c camera vÃ  giáº£i phÃ³ng tÃ i nguyÃªn.
        """
        self.running_mode = None
        if self.cap and self.cap.isOpened():
            self.cap.release()
        self.cap = None
        print("â¹ Stream Ä‘Ã£ dá»«ng.")